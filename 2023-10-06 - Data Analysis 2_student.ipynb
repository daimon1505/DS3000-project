{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9772a3-1e80-4aa4-a64f-ccb285651928",
   "metadata": {},
   "source": [
    "As part of your homework today, please fill out this form: https://forms.gle/QmhjRur2HKopBRLb6\n",
    "\n",
    "We're going to be using the `statsmodels` library today, so please make sure you install it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8823878-2d12-4475-bf7c-9fd8a7b8be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d9cc1-bcde-4414-85bf-882d10d86ed2",
   "metadata": {},
   "source": [
    "# Regression vs Classification\n",
    "* **Regression** is about predicting a continuous number (like what's the temeprature going to be tomorrow given the air pressure, wind speed, and the temperature today?).\n",
    "* This is as opposed to **classification**, which is about predicting a label from a limited set of possible labels (like is it going to rain tomorrow? Yes or No?)\n",
    "\n",
    "\n",
    "# Linear Regression\n",
    "**Linear** regression is about finding a linear formula that best describes given data.\n",
    "\n",
    "Let's start with one dimension, i.e. we will be predicting our value just based on one input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198bc6d0-0cc7-4787-a60d-7b70d617dd0c",
   "metadata": {},
   "source": [
    "Linear regression will help us find a straight line of best fit to these points to describe the relationship between $x$ and $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459eabdd-2d7e-45c9-861f-eef8679f1cef",
   "metadata": {},
   "source": [
    "Let's say we have a dataset that describes how long students prepared for an exam and what score they got in that exam.\n",
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7346357-2e01-43ff-be45-40f92de3c1e4",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcf040-7237-406a-9bdf-de182bb2bd65",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634c500-a73a-4d4b-81c4-be7f12840afa",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71e37d-730d-4b15-bc0c-44a6a8b51201",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75beea8-4d45-4f9a-8e38-52beac9c074f",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bfe47f-323d-4728-a05f-f8ca67c1a415",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765a37e-0762-4e07-ab5f-0e42eaad0627",
   "metadata": {},
   "source": [
    "![lin_reg1](https://sapiezynski.com/algoaudits/lr_08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec8f28-30cd-44b8-9946-3bb5e0d093ce",
   "metadata": {},
   "source": [
    "What are the values of intercept and slope in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68484c1-66f4-428e-8550-5f545b9c6bcc",
   "metadata": {},
   "source": [
    "And so, linear regression lets us describe the relationship between $y$ and $x$ following this linear formula:\n",
    "$$ test\\_score = \\beta_0 + \\beta_1time\\_spent, $$\n",
    "where $\\beta_0$ is the intercept and $\\beta_1$ is the slope.\n",
    "\n",
    "Remember that the intercept ($\\beta_0$) is the predicted value when $x=0$ and the slope ($\\beta_1$) is the change in $y$ associated with a **unit change** in $x$.\n",
    "\n",
    "We can use linear regression to describe relationships with more dimensions (variables) too:\n",
    "$$ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n $$\n",
    "Here each $x_1, ..., x_n$ is a different dimension/variable, for example:\n",
    "* the student's attendance\n",
    "* their GPA\n",
    "* the number of the month when they were born\n",
    "\n",
    "Of course, not all variables will be predictive of the performance in test. Hopefully the coefficient associated with the month number will be close to 0, indicating that the month is not so important in predicting performance.\n",
    "\n",
    "Let's load this data and and fit our linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631acca-b98b-4ce6-a701-cbb417bc6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://sapiezynski.com/algoaudits/lin_regression.csv')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2280e9f-ea9e-465d-92c8-d8f3f9c07f0b",
   "metadata": {},
   "source": [
    "When doing regression using the popular library `statsmodels` we will have to add a constant to find the intercept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56277ea9-e614-4b11-9ccb-feeab6035b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "dataset = add_constant(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc58d9-508a-451b-b097-e94ff0b2ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(dataset['test_score'], dataset[['const', 'hours_of_studying', 'month_of_birth']]).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1400c-7727-4f5a-bfca-7fd7f46361c5",
   "metadata": {},
   "source": [
    "Linear regression might not be a very powerful model, but it offers a clear interpretation/explanation in suitable problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327ccac-3d66-4688-b7e9-5d61eed50a22",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "**Logistic** regression is mostly used for binary classification (confusing!), predicting:\n",
    "* \"yes\" vs \"no\",\n",
    "* \"success\" vs \"failure\",\n",
    "* \"**is** on top of amazon search results\" vs \"**is not** on top of amazon search results\".\n",
    "\n",
    "Its formula looks similar to the linear regression, but now the outcome variable is the logarithm of odds of success instead of $y$.\n",
    "\n",
    "$$ \\ln(\\frac{\\pi}{1-\\pi}) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... $$\n",
    "\n",
    "where $\\pi$ is the probability of success, so $1-\\pi$ is the probability of failure.\n",
    "\n",
    "The values of all of the $\\beta$s will come from `statsmodels` once we fit the model with the data.\n",
    "The values of the different $x$s will be the values of our variables: `reviews_delta`, `stars delta`, `is_amazon_delta`, `is_ad_delta`.\n",
    "So the right side of the equation will be a given, but what does the left side mean?\n",
    "\n",
    "The left side is the log odd ratios, and a unit change in $x_1$ corresponds to $\\beta_1$ change in log odd ratios.\n",
    "\n",
    "Unfortunately, \"log odds ratio\" is not something we can easily interpret.\n",
    "\n",
    "To be able to describe the model weights with intuitive language, let's rewrite this formula to calculate the probability of success $\\pi$ from the values of $x$ directly:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\ln(\\frac{\\pi}{1-\\pi}) &= \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Remeber that logarithm is the inverse function to exponentiation and $\\ln$ is the logarithm with $e$ in the base, $\\ln x=\\log_e x$. To get rid of the logarithm we raise $e$ to the power of both sides of the equation:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\pi}{1-\\pi} &= e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Then we multiply both sides by $(1-\\pi)$, and then transform to get $\\pi$:\n",
    "$$\\begin{align}\n",
    "{\\pi} &= ({1-\\pi})e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...} \\\\\n",
    "{\\pi} &= e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}-\\pi e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "{\\pi}(1+e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}) &= e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...} \\\\\n",
    "{\\pi} &= \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}}{1+e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}}\n",
    "\\end{align}$$\n",
    "\n",
    "So, while we cannot directly say from that a unit change of $x_1$ corresponds to a certain change in the probability of the outcome, we can just plug zeros and ones into the equation above and compute the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7f66c-e351-4b15-abd6-f4b8cbb0dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the dataset from Wednesday\n",
    "pairs_dataset = pd.read_csv('pairs_dataset.csv')\n",
    "\n",
    "pairs_dataset.dropna(inplace=True)\n",
    "pairs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d75678-a839-4d3f-a349-4447556e7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the train/test split as last time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(pairs_dataset, \n",
    "                               test_size=0.2, \n",
    "                               stratify=pairs_dataset['is_placed_higher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6bac43-1126-4e43-a3c8-48f8f7d60b23",
   "metadata": {},
   "source": [
    "Let's start with a model that only has the intercept (constant) and `is_amazon_delta` as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab802e-2fdc-47fe-b82a-2a8506663288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# adding the intercept as a variable\n",
    "train = add_constant(train)\n",
    "\n",
    "# selecting which features to train on\n",
    "features = ['const', 'is_amazon_delta']\n",
    "\n",
    "# training a logistic regression model. First the dependent (outcome variable), then the features\n",
    "log_reg = sm.Logit(train['is_placed_higher'], train[features]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf31a2-726d-43b1-8b5a-3c6677d19309",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ef69c-3aad-497a-bf01-143195351dd2",
   "metadata": {},
   "source": [
    "We will mostly be looking at the bottom table.\n",
    "\n",
    "As a reminder: this is the equation for probability in Logistic Regression:\n",
    "\n",
    "$$ {\\pi} = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}}{1+e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...}} $$\n",
    "\n",
    "`const` (the intercept) translates to the probability $\\pi$ (of product A being on top of the results list) if all other variables are equal to 0\n",
    "\n",
    "$$ \\pi = \\frac{e^{\\beta_{const}}}{1+e^{\\beta_{const}}} $$\n",
    "\n",
    "Let's calculate what that is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97003f-d2a6-4d16-a822-375a974cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "const = log_reg.params['const']\n",
    "\n",
    "np.e**const/(1+np.e**const) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb976782-98bf-45d4-8890-2fcb664120a5",
   "metadata": {},
   "source": [
    "This should be very close to 50% (or 0.5). We look at the intercept when all the variables are zero. In our case there is only one variable, `is_amazon_delta`, which means that either:\n",
    "1. Both products are from amazon brands, or\n",
    "2. Neither of the products is from amazon brands.\n",
    "\n",
    "We don't have a way to differentiate them, so it's a coin toss (50%)\n",
    "\n",
    "The other coefficients describe the change in odds that corresponds to a unit change in the variable.\n",
    "* if the coefficient is positive, it means that an **increase** of variable corresponds to an **increase** in the odds of the positive outcome\n",
    "* if the coefficient is positive, it means that an **increase** of variable corresponds to an **decrease** in the odds of the positive outcome\n",
    "\n",
    "\n",
    "So what happens when `is_amazon_delta` is equal to 1, i.e. product A is an amazon product and product B isn't?\n",
    "By looking at the table with the regression summary we already know it's going to go up (because the coefficient is positive). But by how much? Let's calculate:\n",
    "\n",
    "\n",
    "$$ \\pi = \\frac{e^{\\beta_{const} + \\beta_{is\\_amazon\\_delta}}}{1+e^{\\beta_{const} + \\beta_{is\\_amazon\\_delta}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277d406-d640-4558-9fb0-b9c0c689fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numerator = np.e**(log_reg.params['const'] + log_reg.params['is_amazon_delta'])\n",
    "print(numerator/(1+numerator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444627d5-43ec-4d98-93a9-14ef21569642",
   "metadata": {},
   "source": [
    "That means that in this dataset 93\\% of the time we have two products where one is from amazon and the other isn't, it's the amazon product that will be on the first place.\n",
    "\n",
    "Is our investigation solved? Well no, because maybe this is just because amazon products have higher ratings or more reviews. Let's include the rating difference in the analysis to **control** for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063afa7f-b795-44b9-a346-788e96616972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['const', 'is_amazon_delta','rating_delta']\n",
    "log_reg = sm.Logit(train['is_placed_higher'], train[features]).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e30ba-5441-4c8d-af16-3a458ae3ea39",
   "metadata": {},
   "source": [
    "Now notice the last two columns - that's the 95% confidence interval. The model estimates that the \"real\" value of the coefficient is between these two numbers. If one value is positive, and the other negative, the interval includes 0, which means we can't really tell if the effect is positive, or negative. We say that **it's not significant**. \n",
    "\n",
    "Turns out, controling for the rating difference doesn't change anything and the difference between ratings of the two products do not have a statistically significant relationship with the order of products in this setup.\n",
    "\n",
    "Let's add the review delta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f92722-5aa9-4cbc-aed2-89540d001f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['const', 'is_amazon_delta','rating_delta', 'review_count_delta']\n",
    "log_reg = sm.Logit(train['is_placed_higher'], train[features]).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ad788-b284-4209-9cfe-563fcc5ca597",
   "metadata": {},
   "source": [
    "Same story, let's also include the ad delta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c52f8e-29dd-4ef8-b666-73ab189d4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['const', 'is_amazon_delta','rating_delta', 'review_count_delta', 'is_ad_delta']\n",
    "log_reg = sm.Logit(train['is_placed_higher'], train[features]).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e1487-cc43-4551-ab22-98d856b2bde3",
   "metadata": {},
   "source": [
    "The only other significant coefficient is `is_ad_delta`. How do we interpret its value?\n",
    "\n",
    "Let's take two products, such that:\n",
    "* neither of them are from amazon, so `is_amazon_delta`=0\n",
    "* they have the same rating, so `is_rating_delta`=0\n",
    "* they have the same review count, so `review_count_delta`=0\n",
    "* product A is an ad and product B is not, so `is_ad_delta`=0\n",
    "\n",
    "Now we can plug these values into the equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7051c25-ed9b-4bd5-a4e6-da4409f4f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.e**(log_reg.params['const']\\\n",
    "                   + log_reg.params['is_amazon_delta'] * 0\\\n",
    "                   + log_reg.params['rating_delta'] * 0\\\n",
    "                   + log_reg.params['review_count_delta'] * 0\\\n",
    "                   + log_reg.params['is_ad_delta'] * 1)\n",
    "\n",
    "print(numerator/(1+numerator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12280150-0f75-48ac-8158-f76527fb82ac",
   "metadata": {},
   "source": [
    "That's the probability the ad will be displayed first over an equivalent product that is not an ad.\n",
    "\n",
    "Let's take another example.\n",
    "Products A and B have the same mean rating and are not ads.\n",
    "Product A is from amazon brands. \n",
    "Product B is not, but it has 500,000 reviews more. What is the probability that A is displayed first?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb5bf9-c9a6-400e-9a9b-ba4f6de7e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.e**(log_reg.params['const']\\\n",
    "                   + log_reg.params['is_amazon_delta'] * 1\\\n",
    "                   + log_reg.params['rating_delta'] * 0\\\n",
    "                   + log_reg.params['review_count_delta'] * (-500000)\\\n",
    "                   + log_reg.params['is_ad_delta'] * 0)\n",
    "\n",
    "print(numerator/(1+numerator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3c7f4-0596-428e-8493-da1616c07b98",
   "metadata": {},
   "source": [
    "500,000 more reviews are not enough to beat the Amazon advantage! What about a 800,000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6a523-2fd0-4e1b-89b7-fa774cfc1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.e**(log_reg.params['const']\\\n",
    "                   + log_reg.params['is_amazon_delta'] * 1\\\n",
    "                   + log_reg.params['rating_delta'] * 0\\\n",
    "                   + log_reg.params['review_count_delta'] * (-800000)\\\n",
    "                   + log_reg.params['is_ad_delta'] * 0)\n",
    "\n",
    "print(numerator/(1+numerator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f24381-0e0a-4d60-a493-1a7822ff4c41",
   "metadata": {},
   "source": [
    "There we go, if a non-amazon product has more than 800,000 reviews more than a similar amazon product, it might be displayed higher. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa719c25-ea9d-4d14-9c2f-f8b5083bfd8a",
   "metadata": {},
   "source": [
    "## Actually using logistic regression in practice.\n",
    "All of this math was to show you that there is a real meaning behind these numbers. It would of course be very impractical if we had to manually calculate this every time, so we can just use the model to compute these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d26c66-4869-4665-bdf8-7b5a2a9dbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict([[1, 1, 0, -800000, 0]]) # be careful with the feature order here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f2281-1590-442b-9c6a-11c2699976f9",
   "metadata": {},
   "source": [
    "You might also recall that I said logistic regression is usually used for binary classification, rather than predicting a continuous number, like we've been doing so far.\n",
    "\n",
    "In practice, it means that we apply a threshold at 0.5:\n",
    "* If the output of logistic regression is higher than 0.5, we say it's a positive prediction (in our case product A is displayed on top).\n",
    "* If the output is lower than 0.5, we say it's a negative prediction  (in our case product B is displayed on top).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8a8b4-2345-44f0-b4e8-6d8308619979",
   "metadata": {},
   "source": [
    "# Logistic Regression vs RandomForests\n",
    "We've now shown that Logistic Regression gave us similar results to RandomForest from last class: that a product being from amazon is the most predictive variable of whether it comes on top. Being an ad is also important though less and the difference in the count of reviews barely matters in the face of the other two variables.\n",
    "\n",
    "It also let us quantify how much exactly these variables matter.\n",
    "\n",
    "But leaving interpretability aside, does it do as well as RandomForests at actually predicting which product comes on top? Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0ffc5-bb46-4f64-a602-9288b0572de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_constant(test)\n",
    "y_pred = log_reg.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09faa5-f780-4be8-afc7-f200ba802c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_pred > 0.5) == test['is_placed_higher']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280787bc-35c1-4b23-b203-4da28bb3ea08",
   "metadata": {},
   "source": [
    "Compared to the RandomForests on the same train/test split:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40bad8-2049-4cae-90d3-baab80252f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, # how many trees?\n",
    "                             max_depth = 3, # the deeper the tree the more accuracy in training but more potential for overfitting\n",
    "                             max_features = 4) # the more features more accuracy in training but more potential for overfitting\n",
    "\n",
    "clf.fit(train[features], train['is_placed_higher'])\n",
    "y_pred_rf = clf.predict(test[features])\n",
    "(y_pred_rf == test['is_placed_higher']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a1a266-9cfd-4d95-874a-c4bb21fbdbf4",
   "metadata": {},
   "source": [
    "As we know from last class, this number is feeble and changes as we change the train/test split, but the point is that LogisticRegression is necessarily more interpretable, and sometimes this doesn't even come at a cost of predictive perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2a71f-fd3e-4909-a192-1818a97a7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://www.sapiezynski.com/cs4910/markup/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4d121-5c21-464e-a66a-42191e7f7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4d67f-f0b9-4841-b86d-8c3d20c20031",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['search_term', 'placed_higher',\\\n",
    "            'stars_delta', 'reviews_delta','is_shipped_by_amazon',\\\n",
    "            'is_sold_by_amazon','is_amazon','is_top_clicked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5741697-8df2-4b12-9f80-7a1205df251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['is_shipped_by_amazon',\\\n",
    "            'is_sold_by_amazon','is_amazon','is_top_clicked']:\n",
    "    data[key] /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fa7f3-c8cc-4073-a259-e32ce5207c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[features].to_csv('the_markup.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09856cb0-18de-4332-97cf-488001890d72",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "1. Load the data originally published by The Markup:\n",
    "```python\n",
    "markup_df = pd.read_csv('https://www.sapiezynski.com/algoaudits/the_markup.csv') \n",
    "```\n",
    "2. Make sure to add the constant so you can compute the intercept.\n",
    "2. Decide which features (columns) you will use in the analysis - use all that make sense to include.\n",
    "4. Split the data into train and test sets\n",
    "5. Train a Logistic Regression model on the training set and inspect the coefficients.\n",
    "6. Answer the following questions:\n",
    "    1. Which variables have statistically significant coefficients?\n",
    "    2. Increases in which variables correspond to higher probability of product A coming on top?\n",
    "    3. What's the probability that product A will be displayed above B if:\n",
    "       * B is an amazon brand product and A is not\n",
    "       * B has 1,000,000 more reviews than A\n",
    "       * A is top clicked and B is not\n",
    "       * other variables are the same\n",
    "    3. Perform the same calculation but now B has only 1,000 more reviews than A. Is this what you expected? Why yes/no?\n",
    "    4. All other things equal, what's the probability that the amazon product comes on top if the other product is not from amazon?\n",
    "7. Don't forget to fill out the form! https://forms.gle/QmhjRur2HKopBRLb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29a8ae-3a68-4d6e-8d12-b8f180ad035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_df = pd.read_csv('https://www.sapiezynski.com/algoaudits/the_markup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a0566-4949-4bfc-9f53-3cf573e205c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db52f3a-7ee0-4535-9cd0-47af572acd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
